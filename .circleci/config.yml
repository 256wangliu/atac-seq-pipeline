# Define action tags here

defaults: &defaults
  docker:
    - image: google/cloud-sdk:latest #circleci/buildpack-deps:xenial-scm
  working_directory: ~/atac-seq-pipeline

machine_defaults: &machine_defaults
  machine: 
    image: circleci/classic:201808-01
  working_directory: ~/atac-seq-pipeline

make_tag: &make_tag
  name: make docker image tag
  command: |
    echo "export TAG=encodedcc/atac-seq-pipeline:${CIRCLE_BRANCH}_${CIRCLE_WORKFLOW_ID}" >> ${BASH_ENV}

commands:
  install_python3_and_caper:
    description: "Install python workflow requirements"
    steps:
      - run: pyenv global 3.7.0
      - run: pip install --upgrade pip
      - run: pip install caper

# Define jobs here
version: 2
jobs:
  build:
    <<: *defaults
    steps:
      - checkout
      - setup_remote_docker
      - run: *make_tag
      - run:
          name: build image
          command: |
            source ${BASH_ENV}
            export DOCKER_CACHE_TAG=v1.7.1
            echo "pulling ${DOCKER_CACHE_TAG}!"
            docker pull encodedcc/atac-seq-pipeline:${DOCKER_CACHE_TAG}
            docker login -u=${DOCKERHUB_USER} -p=${DOCKERHUB_PASS}
            docker build --cache-from encodedcc/atac-seq-pipeline:${DOCKER_CACHE_TAG} --build-arg GIT_COMMIT_HASH=${CIRCLE_SHA1} --build-arg BRANCH=${CIRCLE_BRANCH} --build-arg BUILD_TAG=${TAG} -t $TAG -f dev/docker_image/Dockerfile .
            docker push ${TAG}
            docker logout
  test_tasks:
    <<: *machine_defaults
    steps:
      - checkout
      - run: *make_tag
      - run:
          no_output_timeout: 300m
          command: |
            source ${BASH_ENV}

            cd dev/test/test_task/
            rm -rf atac-seq-pipeline-test-data
            export BOTO_CONFIG=/dev/null
            gsutil -m cp -r gs://encode-pipeline-test-samples/encode-atac-seq-pipeline/atac-seq-pipeline-test-data .
            ./download_hg38_fasta_for_test_ataqc.sh
            for wdl in test_*.wdl
            do
              json=${wdl%.*}.json
              result=${wdl%.*}.result.json
              ./test.sh ${wdl} ${json} ${TAG}
              if [[ $(wc -l "${result}" | awk '{print $1}') > 1 ]]; then
                python -c "import sys; import json; data=json.loads(sys.stdin.read()); sys.exit(int(not data[u'match_overall']))" < ${result}
              fi
              rm -f ${result}
            done
            
  test_workflow_se:
    <<: *machine_defaults
    steps:
      - checkout
      - run: *make_tag
      - run:
          no_output_timeout: 300m
          command: |
            source ${BASH_ENV}
            gcloud --quiet config set project ${GOOGLE_PROJECT_ID}
            cd dev/test/test_workflow/
            echo ${GCLOUD_SERVICE_ACCOUNT_SECRET_JSON} > tmp_key.json
            ./test_atac.sh ENCSR889WQX_subsampled.json tmp_key.json ${TAG}
            python -c "import sys; import json; data=json.loads(sys.stdin.read()); sys.exit(int(not data[u'outputs'][u'atac.qc_json_ref_match']))" < ENCSR889WQX_subsampled.metadata.json

  test_workflow_unrep_se:
    <<: *machine_defaults
    steps:
      - checkout
      - install_python3_and_caper
      - run: *make_tag
      - run:
          no_output_timeout: 300m
          command: |
            INPUT=ENCSR889WQX_subsampled_unrep.json
            source ${BASH_ENV}
            gcloud --quiet config set project ${GOOGLE_PROJECT_ID}
            cd dev/test/test_workflow/
            echo ${GCLOUD_SERVICE_ACCOUNT_SECRET_JSON} > tmp_secret_key.json
            caper run ../../../chip.wdl --backend gcp --out-gcs-bucket gs://encode-pipeline-test-runs/circleci -i ${INPUT} --docker ${TAG} -m metadata.json --backend-file backend_gcp_service_account.conf
            (($(jq '.outputs["chip.qc_json_ref_match"]' metadata.json)==false)) && exit 1

  test_workflow_pe:
    <<: *machine_defaults
    steps:
      - checkout
      - run: *make_tag
      - run:
          no_output_timeout: 300m
          command: |
            source ${BASH_ENV}
            gcloud --quiet config set project ${GOOGLE_PROJECT_ID}
            cd dev/test/test_workflow/
            echo ${GCLOUD_SERVICE_ACCOUNT_SECRET_JSON} > tmp_key.json
            ./test_atac.sh ENCSR356KRQ_subsampled.json tmp_key.json ${TAG}
            python -c "import sys; import json; data=json.loads(sys.stdin.read()); sys.exit(int(not data[u'outputs'][u'atac.qc_json_ref_match']))" < ENCSR356KRQ_subsampled.metadata.json

  test_workflow_pe_start_from_bam:
    <<: *machine_defaults
    steps:
      - checkout
      - run: *make_tag
      - run:
          no_output_timeout: 300m
          command: |
            source ${BASH_ENV}
            gcloud --quiet config set project ${GOOGLE_PROJECT_ID}
            cd dev/test/test_workflow/
            echo ${GCLOUD_SERVICE_ACCOUNT_SECRET_JSON} > tmp_key.json
            ./test_atac.sh ENCSR356KRQ_subsampled_start_from_bam.json tmp_key.json ${TAG}
            python -c "import sys; import json; data=json.loads(sys.stdin.read()); sys.exit(int(not data[u'outputs'][u'atac.qc_json_ref_match']))" < ENCSR356KRQ_subsampled_start_from_bam.metadata.json


# Define workflow here
workflows:
  version: 2
  build_workflow:
    jobs:
      - build
      - test_tasks:
          requires:
            - build
      #- test_workflow_se:
      #    requires:
      #      - build
      - test_workflow_unrep_se:
          requires:
            - build
      #- test_workflow_pe:
      #    requires:
      #      - build
      #- test_workflow_pe_start_from_bam:
      #    requires:
      #      - build
